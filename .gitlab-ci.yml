# Use stages to define stages that contain groups of jobs. Use stage in a job
# to configure the job to run in a specific stage.
stages:
  - test

# Global default environment variables set for all jobs unless overridden by
# job-specific configuration.
variables:
  # Make sure output supports UTF-8
  LC_ALL: "C.UTF-8"
  LANG: "C.UTF-8"

# Global default parameters set for all jobs unless overridden by job-specific
# configuration.
default:
  image: python:3.8
  interruptible: true

###############################################################################
# Run Conditions
#
# In the future, this could be broken out into a separate file that we
# `include` here.
#
# REMINDER: The "." prefix causes the "job" to be hidden (does not get run),
# but can still be used for inheritance.

# Run rules to activate at the major junction points: merge requests, tag
# pipelines and branch pipelines for main.
.run_automatically:
  rules:
    # If changes are make to an active merge request.
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: on_success
    # If changes are pushed for a tag.
    - if: $CI_COMMIT_TAG
      when: on_success
    # If changes are pushed to the default branch.
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: on_success
    - when: never  # explicit fail-exclude terminal condition.

###############################################################################
# Jobs -- Testing
#
# In the future, `.`-prefixed templates could be broken out into a separate
# file that we `include` here.
#
# REMINDER: The "." prefix causes the "job" to be hidden (does not get run),
# but can still be used for inheritance.

# For internal git dependencies
.setup_ci_git: &setup_ci_git
  # pyBSM has a series of .bin files saved as git-lfs objects,
  # when installing from a repo directly poetry uses dulwich
  # by default to install git repos. Dulwich does not currently
  # support git-lfs, so instead we install git-lfs here and
  # include a local poetry.toml in the repo. The purpose for
  # including it in the repo rather than as a command here is
  # so that it is the default used when developing locally.
  - curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash
  - apt-get install -y git-lfs
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.jatic.net".insteadof "ssh://git@gitlab.jatic.net"
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.jatic.net/".insteadOf "git@gitlab.jatic.net:"

.poetry_install:
  variables:
    # Change pip's cache directory to be inside the project directory since we
    # can only cache local items. Same for poetry cache
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
    POETRY_CACHE_DIR: "$CI_PROJECT_DIR/.cache/poetry"
  # We are only caching the pip/poetry caches, NOT THE VENV. Caches should be
  # python version agnostic.
  cache:
    key: py-package-cache
    paths:
      - $PIP_CACHE_DIR
      - $POETRY_CACHE_DIR
  before_script:
    - *setup_ci_git
    - export PATH=${HOME}/.local/bin:${PATH}
    # Will make use of .cache/pip
    - pip install --user -U poetry
    - command -v python
    - python --version
    - command -v pip
    - pip --version
    - command -v poetry
    - poetry -V
    - poetry config --local virtualenvs.in-project true
    # Will make use of .cache/poetry
    - poetry install --sync

.test_preamble:
  extends:
    - .run_automatically
  stage: test
  image: python:3.8
  interruptible: true
  tags:
    - kitware

.test_defaults:
  extends:
    - .test_preamble
    - .poetry_install


# Job to lint python code
test-py-lint:
  extends: .test_defaults
  script:
    - poetry run flake8

# Job to typecheck python code
test-py-typecheck:
  extends: .test_defaults
  script:
    - poetry run mypy

test-docs-build:
  extends: .test_defaults
  script:
    - cd docs
    - poetry run make html

# Job to run unittests via pytest
test-pytest:
  extends: .test_defaults
  parallel:
    matrix:
      - PY_VERSION: [ "3.8", "3.9", "3.10", "3.11" ]
  image: python:${PY_VERSION}
  script:
    - poetry run pytest

# Job to check the release notes folder
test-release-notes-check:
  extends: .test_preamble
  script:
    - git fetch
    - scripts/check_for_release_notes.sh origin/${CI_MERGE_REQUEST_TARGET_BRANCH_NAME}
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_COMMIT_TITLE =~ /Merge branch.*/
      when: never
    - if: $CI_COMMIT_BRANCH == "release" && $CI_COMMIT_TITLE =~ /Merge branch.*/
      when: never
    - !reference [.run_automatically, rules] # Don't overwrite normal rules

# Job to test-run the example jupyter notebooks
#
# This job has a parallel matrix to parameterize different working-directories
# and notebooks within to run. Each parallel instance of this job should only
# run a single notebook. !reference:
#
# See GitLab docs for parallel-matrix functionality:
#   https://docs.gitlab.com/ee/ci/yaml/#parallelmatrix
#
# The parallel-matrix list may have multiple items, and each entry should have
# a pair of keys: "NOTEBOOK_DIR" and "NOTEBOOK_FILE". (Given the documentation
# for the parallel-matrix functionality, combinatorics are only applied within
# an item, not across items.)
# * "NOTEBOOK_DIR" should be a single string that notes the directory in which
#   notebook files should be run in (basically the working directory, generally
#   the directory the notebook lives in). This path should be relative to the
#   root of the repository.
# * "NOTEBOOK_FILE" should be a list of strings that denote the notebook files
#   to be run. These paths path should be relative to the "NOTEBOOK_DIR". Files
#   in this list will be combinatorially combined with the path provided in
#   the associated "NOTEBOOK_DIR" to create a job parameterization instance.
test-notebooks:
  extends: .test_defaults
  variables:
    TORCH_HOME: "${CI_PROJECT_DIR}/.cache/torch"
  tags:
    - kitware
  # Merge inherited caches
  cache:
    - !reference [.test_defaults, cache]
    - key: dummy-cache
      paths:
        - ${TORCH_HOME}
  # Specifying the various notebooks that we want to be tested. Each invocation
  # of this job should try to execute only one notebook via papermill.
  parallel:
    matrix:
      # Sequences combinatorically combine within a list entry
      - NOTEBOOK_DIR: "examples"
        NOTEBOOK_FILE: [ 
          "coco_scorer.ipynb",
          "generator.ipynb",
          "perturbers.ipynb"
        ]
      - NOTEBOOK_DIR: "examples/jatic_toolbox"
        NOTEBOOK_FILE: [ "augmentations.ipynb" ]
  # Using default container image defined above
  script:
    - cd "${NOTEBOOK_DIR}"
    - poetry run papermill
        --progress-bar -k python3 --stdout-file - --stderr-file -
        "${NOTEBOOK_FILE}" /dev/null
