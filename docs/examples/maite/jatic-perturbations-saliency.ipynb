{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb8c0b4",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [12]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f4fd3",
   "metadata": {
    "papermill": {
     "duration": 0.006514,
     "end_time": "2026-02-17T01:59:27.427617",
     "exception": false,
     "start_time": "2026-02-17T01:59:27.421103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploring the Effects of Perturbations on Saliency Map Generation\n",
    "\n",
    "The link between saliency maps and model natural robustness is currently unclear. This is a simple notebook exploring how perturbations might affect saliency maps, using tools provided by the `nrtk` and `xaitk-saliency` packages.\n",
    "\n",
    "## Table of Contents\n",
    "* [Environment Setup](#environment-setup)\n",
    "* [Example Images](#example-images)\n",
    "* [Defining the \"Application\"](#defining-the-application)\n",
    "* [Running the \"Application\"](#running-the-application)\n",
    "    * [Classifier](#classifier)\n",
    "    * [Saliency Generator](#saliency-generator)\n",
    "    * [Results](#results)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Kitware/nrtk/blob/main/docs/examples/maite/jatic-perturbations-saliency.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7b4e6",
   "metadata": {
    "papermill": {
     "duration": 0.003852,
     "end_time": "2026-02-17T01:59:27.435396",
     "exception": false,
     "start_time": "2026-02-17T01:59:27.431544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set Up the Environment <a name=\"environment-setup\"></a>\n",
    "\n",
    "**Note for Colab users**: After setting up the environment, you may need to \"Restart Runtime\" in order to resolve package version conflicts (see the [README](https://github.com/Kitware/nrtk/blob/main/docs/examples/README.md#run-the-notebooks-from-colab) for more info)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27c385",
   "metadata": {},
   "source": [
    "Note: We are suppressing warnings within this notebook to reduce visual clutter for demonstration purposes. If any issues arise while executing this notebook, we recommend that this cell is **not** executed so that any related warnings are shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef01c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44b964e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T01:59:27.443764Z",
     "iopub.status.busy": "2026-02-17T01:59:27.443603Z",
     "iopub.status.idle": "2026-02-17T02:01:38.373990Z",
     "shell.execute_reply": "2026-02-17T02:01:38.373396Z"
    },
    "papermill": {
     "duration": 130.935328,
     "end_time": "2026-02-17T02:01:38.374327",
     "exception": false,
     "start_time": "2026-02-17T01:59:27.438999",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installing nrtk with required extras...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installing notebook-specific packages...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected status of NRTK extras and their dependencies:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[albumentations]\n",
      "  - nrtk-albumentations       ✗ missing\n",
      "\n",
      "[diffusion]\n",
      "  - torch                     ✓ 2.10.0\n",
      "  - diffusers                 ✗ missing\n",
      "  - accelerate                ✗ missing\n",
      "  - Pillow                    ✓ 12.1.1\n",
      "  - transformers              ✓ 5.2.0\n",
      "  - protobuf                  ✗ missing\n",
      "\n",
      "[graphics]\n",
      "  - opencv-python             ✗ missing\n",
      "\n",
      "[headless]\n",
      "  - opencv-python-headless    ✓ 4.13.0.92\n",
      "\n",
      "[maite]\n",
      "  - maite                     ✓ 0.9.2\n",
      "\n",
      "[pillow]\n",
      "  - Pillow                    ✓ 12.1.1\n",
      "\n",
      "[pybsm]\n",
      "  - pybsm                     ✓ 0.14.3\n",
      "\n",
      "[skimage]\n",
      "  - scikit-image              ✗ missing\n",
      "\n",
      "[tools]\n",
      "  - kwcoco                    ✗ missing\n",
      "  - Pillow                    ✓ 12.1.1\n",
      "  - click                     ✓ 8.3.1\n",
      "  - fastapi                   ✗ missing\n",
      "  - uvicorn                   ✗ missing\n",
      "  - pydantic                  ✗ missing\n",
      "  - pydantic-settings         ✗ missing\n",
      "  - python-json-logger        ✗ missing\n",
      "\n",
      "[waterdroplet]\n",
      "  - scipy                     ✓ 1.17.0\n",
      "  - numba                     ✓ 0.63.1\n",
      "\n",
      "\n",
      "For details about installing NRTK extras, please visit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    https://nrtk.readthedocs.io/en/stable/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pip\n",
    "print(\"Installing nrtk with required extras...\")\n",
    "%pip install -q \"nrtk[pybsm,headless]\"\n",
    "print(\"Installing notebook-specific packages...\")\n",
    "%pip install -q xaitk-jatic \"datasets>=3.4.0\" transformers tabulate torch\n",
    "print(\"Done!\")\n",
    "\n",
    "from nrtk.utils._extras import print_extras_status  # noqa: E402 - intentionally after %pip install\n",
    "\n",
    "print_extras_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14d93f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:38.388853Z",
     "iopub.status.busy": "2026-02-17T02:01:38.388609Z",
     "iopub.status.idle": "2026-02-17T02:01:48.105111Z",
     "shell.execute_reply": "2026-02-17T02:01:48.104680Z"
    },
    "papermill": {
     "duration": 9.728596,
     "end_time": "2026-02-17T02:01:48.105603",
     "exception": false,
     "start_time": "2026-02-17T02:01:38.377007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/KHQ/b.richardwebster/Documents/uncontrolled/projects/CDAO/gitlab/nrtk/.tox/papermill/lib/python3.13/site-packages/xaitk_saliency/__init__.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Hashable, Sequence\n",
    "from dataclasses import dataclass, field\n",
    "from typing import TYPE_CHECKING, Any\n",
    "\n",
    "import maite.protocols.image_classification as ic\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from smqtk_classifier.interfaces.classify_image import ClassifyImage\n",
    "from tabulate import tabulate\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    ")\n",
    "from xaitk_jatic.interop.image_classification.model import JATICImageClassifier\n",
    "from xaitk_saliency.impls.gen_image_classifier_blackbox_sal.slidingwindow import SlidingWindowStack\n",
    "from xaitk_saliency.interfaces.gen_image_classifier_blackbox_sal import (\n",
    "    GenerateImageClassifierBlackboxSaliency,\n",
    ")\n",
    "\n",
    "from nrtk.impls.perturb_image.optical.otf import JitterPerturber\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"jpeg\"  # Use JPEG format for inline visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb6ba6",
   "metadata": {
    "papermill": {
     "duration": 0.011005,
     "end_time": "2026-02-17T02:01:48.119601",
     "exception": false,
     "start_time": "2026-02-17T02:01:48.108596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example Images <a name=\"example-images\"></a>\n",
    "\n",
    "We'll use example images from the CIFAR-10 test dataset, but this could be expanded to many images -- even across a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07790a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:48.125922Z",
     "iopub.status.busy": "2026-02-17T02:01:48.125637Z",
     "iopub.status.idle": "2026-02-17T02:01:51.795933Z",
     "shell.execute_reply": "2026-02-17T02:01:51.795339Z"
    },
    "papermill": {
     "duration": 3.674582,
     "end_time": "2026-02-17T02:01:51.797010",
     "exception": false,
     "start_time": "2026-02-17T02:01:48.122428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"cifar10\", split=\"test\")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    assert isinstance(data, Dataset)\n",
    "\n",
    "labels = data.features[\"label\"].names\n",
    "data.set_transform(lambda x: {\"image\": x[\"img\"], \"label\": x[\"label\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68e410e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.807569Z",
     "iopub.status.busy": "2026-02-17T02:01:51.807403Z",
     "iopub.status.idle": "2026-02-17T02:01:51.855142Z",
     "shell.execute_reply": "2026-02-17T02:01:51.854731Z"
    },
    "papermill": {
     "duration": 0.053419,
     "end_time": "2026-02-17T02:01:51.855609",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.802190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 2\n",
    "if TYPE_CHECKING:\n",
    "    assert isinstance(data, Dataset)\n",
    "imgs = np.asarray([np.asarray(data[idx][\"image\"]) for idx in range(num_samples)])\n",
    "ground_truth: list[int] = [data[idx][\"label\"] for idx in range(num_samples)]\n",
    "\n",
    "for img, gt in zip(imgs, ground_truth, strict=False):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(f\"GT: {labels[gt]}\")\n",
    "    _ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f51856",
   "metadata": {
    "papermill": {
     "duration": 0.002752,
     "end_time": "2026-02-17T02:01:51.861548",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.858796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining the \"Application\" <a name=\"defining-the-application\"></a>\n",
    "\n",
    "First we'll define a couple of dataclasses to keep track of results more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6e713e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.868044Z",
     "iopub.status.busy": "2026-02-17T02:01:51.867854Z",
     "iopub.status.idle": "2026-02-17T02:01:51.870901Z",
     "shell.execute_reply": "2026-02-17T02:01:51.870551Z"
    },
    "papermill": {
     "duration": 0.00701,
     "end_time": "2026-02-17T02:01:51.871185",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.864175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PerturbationResult:\n",
    "    \"\"\"Dataclass for storing perturbed image and associated results.\"\"\"\n",
    "\n",
    "    descriptor: str\n",
    "    img: np.ndarray\n",
    "    sal_maps: np.ndarray\n",
    "    pred_class: int\n",
    "    pred_prob: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SaliencyResults:\n",
    "    \"\"\"Dataclass for storing saliency map and associated results.\"\"\"\n",
    "\n",
    "    ref_img: np.ndarray\n",
    "    ref_sal_maps: np.ndarray\n",
    "    gt: int\n",
    "    pred_class: int\n",
    "    pred_prob: float\n",
    "    perturbations: list[PerturbationResult] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204325aa",
   "metadata": {
    "papermill": {
     "duration": 0.002534,
     "end_time": "2026-02-17T02:01:51.876345",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.873811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll define a function to compute specified metrics upon our saliency map results. These metrics include measures such as the entropy of the resulting saliency map, as well as various measures of correlation between the saliency map computed on the original image and the saliency maps computed on perturbed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38449894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.882181Z",
     "iopub.status.busy": "2026-02-17T02:01:51.882057Z",
     "iopub.status.idle": "2026-02-17T02:01:51.887372Z",
     "shell.execute_reply": "2026-02-17T02:01:51.887006Z"
    },
    "papermill": {
     "duration": 0.009088,
     "end_time": "2026-02-17T02:01:51.887947",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.878859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _compute_entropy(\n",
    "    sal_map: np.ndarray,\n",
    "    clip_min: int | None = None,\n",
    "    clip_max: int | None = None,\n",
    ") -> np.number | np.ndarray:\n",
    "    if clip_min is not None or clip_max is not None:\n",
    "        s = np.clip(sal_map, clip_min, clip_max)\n",
    "    else:\n",
    "        s = (sal_map - sal_map.min()) / (sal_map.max() - sal_map.min())\n",
    "    return entropy(s.ravel(), base=2)\n",
    "\n",
    "\n",
    "def _compute_ssd(sal_map: np.ndarray, ref_sal_map: np.ndarray) -> float:\n",
    "    sum_sq_diff = np.sum(np.power(np.subtract(sal_map, ref_sal_map), 2))\n",
    "    norm = np.sqrt(np.sum(np.power(sal_map, 2)) * np.sum(np.power(ref_sal_map, 2)))\n",
    "    if not norm:\n",
    "        return np.inf\n",
    "    return sum_sq_diff / norm\n",
    "\n",
    "\n",
    "def _compute_xcorr(sal_map: np.ndarray, ref_sal_map: np.ndarray) -> float:\n",
    "    def _normalize(s: np.ndarray) -> tuple[np.ndarray, bool]:\n",
    "        s -= s.mean()\n",
    "        std = s.std()\n",
    "\n",
    "        if std:\n",
    "            s /= std\n",
    "\n",
    "        return s, std == 0\n",
    "\n",
    "    s1, c1 = _normalize(sal_map.copy())\n",
    "    s2, c2 = _normalize(ref_sal_map.copy())\n",
    "\n",
    "    if c1 and not c2:\n",
    "        return 0.0\n",
    "    return np.corrcoef(s1.flatten(), s2.flatten())[0, 1]\n",
    "\n",
    "\n",
    "def _compute_metric(sal_map: np.ndarray, ref_sal_map: np.ndarray, m: str) -> float:\n",
    "    if \"entropy\" in m:\n",
    "        _compute_entropy_setup(sal_map, m)\n",
    "    if m == \"ssd\":\n",
    "        return _compute_ssd(sal_map, ref_sal_map)\n",
    "    if m == \"xcorr\":\n",
    "        return _compute_xcorr(sal_map, ref_sal_map)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def _compute_entropy_setup(sal_map: np.ndarray, m: str) -> float | np.number | np.ndarray:\n",
    "    if m == \"entropy\":\n",
    "        return _compute_entropy(sal_map)\n",
    "    if m == \"pos saliency entropy\":\n",
    "        return _compute_entropy(sal_map, 0, 1)\n",
    "    if m == \"neg saliency entropy\":\n",
    "        return _compute_entropy(sal_map, -1, 0)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def _generate_row(\n",
    "    sal_map: np.ndarray,\n",
    "    ref_sal_map: np.ndarray,\n",
    "    row_label: str,\n",
    "    metrics: tuple[str, ...],\n",
    ") -> list[Hashable]:\n",
    "    r: list[Hashable] = [row_label]\n",
    "\n",
    "    r.extend([_compute_metric(sal_map, ref_sal_map, metric.lower().strip()) for metric in metrics])\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def compute_metrics(results: list[SaliencyResults], metrics: tuple[str, ...]) -> None:\n",
    "    \"\"\"Compute metrics for saliency maps.\"\"\"\n",
    "    headers = [\"Perturbation\"]\n",
    "    headers.extend(list(metrics))\n",
    "    for res in results:\n",
    "        rows = []\n",
    "\n",
    "        rows.append(_generate_row(res.ref_sal_maps[res.gt], res.ref_sal_maps[res.gt], \"Ref Image\", metrics))\n",
    "        rows.extend(\n",
    "            [\n",
    "                _generate_row(pert.sal_maps[res.gt], res.ref_sal_maps[res.gt], f\"{pert.descriptor}\", metrics)\n",
    "                for pert in res.perturbations\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        print(tabulate(rows, headers=headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7602444",
   "metadata": {
    "papermill": {
     "duration": 0.002599,
     "end_time": "2026-02-17T02:01:51.893297",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.890698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll also define a function to display all generated saliency maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a79d0639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.899001Z",
     "iopub.status.busy": "2026-02-17T02:01:51.898867Z",
     "iopub.status.idle": "2026-02-17T02:01:51.904169Z",
     "shell.execute_reply": "2026-02-17T02:01:51.903508Z"
    },
    "papermill": {
     "duration": 0.009041,
     "end_time": "2026-02-17T02:01:51.904709",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.895668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _plot_img(img: np.ndarray, num_cols: int, descriptor: str = \"\") -> None:\n",
    "    plt.subplot(2, num_cols, 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(descriptor)\n",
    "\n",
    "\n",
    "def _plot_rows(sal_maps: np.ndarray, num_cols: int, plot_idxes: list[int] | None = None) -> None:\n",
    "    plot_idxes = list(range(len(sal_maps))) if plot_idxes is None else [*set(plot_idxes)]\n",
    "    n_cols = min(num_cols - 1, len(plot_idxes))\n",
    "    n_rows = 2\n",
    "\n",
    "    num_imgs = 0\n",
    "    for r in range(n_rows):\n",
    "        col_offset = 2\n",
    "        if r > 0:\n",
    "            col_offset = 3\n",
    "        for c in range(r * n_cols, min(r * n_cols + n_cols, len(plot_idxes))):\n",
    "            plt.subplot(n_rows, num_cols, c + col_offset)\n",
    "            im = plt.imshow(sal_maps[plot_idxes[c]], cmap=plt.get_cmap(\"RdBu\"), vmin=-1, vmax=1)\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "            plt.xlabel(f\"{labels[plot_idxes[c]]}\")\n",
    "            num_imgs += 1\n",
    "\n",
    "            if num_imgs == len(plot_idxes):\n",
    "                fig = plt.gcf()\n",
    "                cax = fig.add_axes((0.38, 0.60, 0.01, 0.21))  # tweaked for this particular example\n",
    "                plt.colorbar(im, cax=cax)\n",
    "\n",
    "\n",
    "def display_results(results: list[SaliencyResults], labels: dict[int, str]) -> None:\n",
    "    \"\"\"Displays saliency results with plots and a table.\"\"\"\n",
    "    num_classes = len(labels)\n",
    "\n",
    "    for res in results:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        num_cols = np.ceil(num_classes / 2).astype(int) + 1\n",
    "        pred = f\"{labels[res.pred_class]} ({res.pred_prob:.2f})\"\n",
    "        _plot_img(res.ref_img, num_cols, f\"Ref Img\\nGT: {labels[res.gt]}\\nPred: {pred}\")\n",
    "        _plot_rows(res.ref_sal_maps, num_cols, [res.gt])\n",
    "\n",
    "        for pert in res.perturbations:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            pred = f\"{pert.pred_class} ({pert.pred_prob:.2f})\"\n",
    "            _plot_img(pert.img, num_cols, f\"{pert.descriptor}\\nPred: {pred}\")\n",
    "            _plot_rows(pert.sal_maps, num_cols, [res.gt])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebdf216",
   "metadata": {
    "papermill": {
     "duration": 0.002644,
     "end_time": "2026-02-17T02:01:51.910445",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.907801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we'll define the \"application\", which perturbs the given input image(s) to varying degrees and generates saliency maps. In this case, we'll perturb the images using a pyBSM based perturber. To easily apply this perturbation, we'll use the `JitterPerturber`, which simulates varying amounts of sensor jitter on image collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21514b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.916638Z",
     "iopub.status.busy": "2026-02-17T02:01:51.916494Z",
     "iopub.status.idle": "2026-02-17T02:01:51.921760Z",
     "shell.execute_reply": "2026-02-17T02:01:51.920865Z"
    },
    "papermill": {
     "duration": 0.009346,
     "end_time": "2026-02-17T02:01:51.922338",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.912992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _max_class(probs: dict) -> str:\n",
    "    v = list(probs.values())\n",
    "    k = list(probs.keys())\n",
    "    return k[v.index(max(v))]\n",
    "\n",
    "\n",
    "def _generate_augmented_maps(\n",
    "    idx: int,\n",
    "    kwargs: list[dict[str, Any]],\n",
    "    res: SaliencyResults,\n",
    "    img: np.ndarray,\n",
    "    num_images: int,\n",
    "    image_classifier: ClassifyImage,\n",
    "    saliency_generator: GenerateImageClassifierBlackboxSaliency,\n",
    ") -> None:\n",
    "    for k in kwargs:\n",
    "        print(f\"Generating saliency maps for s_y={k['s_y']} (ref image {idx + 1} of {num_images})\")\n",
    "        xform = JitterPerturber(**k)\n",
    "        img_out, _ = xform(image=np.copy(img))\n",
    "        sal_maps = saliency_generator(img_out, image_classifier)\n",
    "        probs = next(image_classifier.classify_images(np.expand_dims(img_out, axis=0)))\n",
    "        pred_class = _max_class(probs)\n",
    "\n",
    "        pert = PerturbationResult(\n",
    "            descriptor=f\"ksize={k}\",\n",
    "            img=img_out,\n",
    "            sal_maps=sal_maps,\n",
    "            pred_class=labels[pred_class],\n",
    "            pred_prob=probs[pred_class],\n",
    "        )\n",
    "\n",
    "        res.perturbations.append(pert)\n",
    "\n",
    "\n",
    "def generate_perturbed_sal_maps(\n",
    "    images: np.ndarray,\n",
    "    ground_truth: list[int],\n",
    "    image_classifier: ClassifyImage,\n",
    "    saliency_generator: GenerateImageClassifierBlackboxSaliency,\n",
    "    kwargs: list[dict[str, Any]],\n",
    "    display_labels: dict[int, str],\n",
    "    display_maps: bool = True,\n",
    "    metrics: tuple[str, ...] = (\"Pos Saliency Entropy\", \"Neg Saliency Entropy\", \"Entropy\", \"SSD\", \"XCorr\"),\n",
    ") -> list[SaliencyResults]:\n",
    "    \"\"\"Generate saliency maps for image.\"\"\"\n",
    "    # Get class labels\n",
    "    labels = image_classifier.get_labels()\n",
    "\n",
    "    # Generate saliency maps\n",
    "    results = []\n",
    "    for idx, img in enumerate(images):\n",
    "        print(f\"Generating saliency maps for reference image (image {idx + 1} of {len(images)})\")\n",
    "        sal_maps = saliency_generator(img, image_classifier)\n",
    "        probs = next(image_classifier.classify_images(np.expand_dims(img, axis=0)))\n",
    "        pred_class = _max_class(probs)\n",
    "        res = SaliencyResults(\n",
    "            ref_img=np.copy(img),\n",
    "            ref_sal_maps=sal_maps,\n",
    "            gt=ground_truth[idx],\n",
    "            pred_class=labels.index(pred_class),\n",
    "            pred_prob=probs[pred_class],\n",
    "        )\n",
    "\n",
    "        _generate_augmented_maps(idx, kwargs, res, img, len(images), image_classifier, saliency_generator)\n",
    "\n",
    "        results.append(res)\n",
    "\n",
    "    for result in results:\n",
    "        # Plot each image in set with saliency maps\n",
    "        if display_maps:\n",
    "            display_results([result], display_labels)\n",
    "\n",
    "        # Compute metrics\n",
    "        compute_metrics([result], metrics)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e781c",
   "metadata": {
    "papermill": {
     "duration": 0.00269,
     "end_time": "2026-02-17T02:01:51.928597",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.925907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running the \"Application\" <a name=\"running-the-application\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49c99a",
   "metadata": {
    "papermill": {
     "duration": 0.003734,
     "end_time": "2026-02-17T02:01:51.935365",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.931631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Classifier <a name=\"classifier\"></a>\n",
    "\n",
    "We'll use a Hugging Face model conforming to the `maite` image classification protocol, along with the relevant `xaitk-saliency` adapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1828e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:51.942317Z",
     "iopub.status.busy": "2026-02-17T02:01:51.942168Z",
     "iopub.status.idle": "2026-02-17T02:01:52.888538Z",
     "shell.execute_reply": "2026-02-17T02:01:52.887736Z"
    },
    "papermill": {
     "duration": 0.950793,
     "end_time": "2026-02-17T02:01:52.889214",
     "exception": false,
     "start_time": "2026-02-17T02:01:51.938421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   0%|          | 1/200 [00:00<00:00, 29330.80it/s, Materializing param=classifier.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   0%|          | 1/200 [00:00<00:00, 2884.67it/s, Materializing param=classifier.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   1%|          | 2/200 [00:00<00:00, 2963.13it/s, Materializing param=classifier.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   1%|          | 2/200 [00:00<00:00, 2194.25it/s, Materializing param=classifier.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▏         | 3/200 [00:00<00:00, 1114.62it/s, Materializing param=vit.embeddings.cls_token]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▏         | 3/200 [00:00<00:00, 969.56it/s, Materializing param=vit.embeddings.cls_token] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▏         | 4/200 [00:00<00:00, 1084.85it/s, Materializing param=vit.embeddings.patch_embeddings.projection.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▏         | 4/200 [00:00<00:00, 987.48it/s, Materializing param=vit.embeddings.patch_embeddings.projection.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▎         | 5/200 [00:00<00:00, 1066.55it/s, Materializing param=vit.embeddings.patch_embeddings.projection.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   2%|▎         | 5/200 [00:00<00:00, 1025.00it/s, Materializing param=vit.embeddings.patch_embeddings.projection.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   3%|▎         | 6/200 [00:00<00:00, 1180.33it/s, Materializing param=vit.embeddings.position_embeddings]               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   3%|▎         | 6/200 [00:00<00:00, 1127.85it/s, Materializing param=vit.embeddings.position_embeddings]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▎         | 7/200 [00:00<00:00, 1264.05it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▎         | 7/200 [00:00<00:00, 1226.40it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▍         | 8/200 [00:00<00:00, 1355.35it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▍         | 8/200 [00:00<00:00, 1320.62it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▍         | 9/200 [00:00<00:00, 1442.39it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   4%|▍         | 9/200 [00:00<00:00, 1405.81it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   5%|▌         | 10/200 [00:00<00:00, 1517.64it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   5%|▌         | 10/200 [00:00<00:00, 1479.99it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▌         | 11/200 [00:00<00:00, 1585.09it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▌         | 11/200 [00:00<00:00, 1550.52it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▌         | 12/200 [00:00<00:00, 1649.68it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▌         | 12/200 [00:00<00:00, 1609.84it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▋         | 13/200 [00:00<00:00, 1698.42it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   6%|▋         | 13/200 [00:00<00:00, 1666.19it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   7%|▋         | 14/200 [00:00<00:00, 1753.94it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   7%|▋         | 14/200 [00:00<00:00, 1722.61it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 15/200 [00:00<00:00, 1691.93it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 15/200 [00:00<00:00, 1659.53it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 16/200 [00:00<00:00, 1730.46it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 16/200 [00:00<00:00, 1700.25it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 17/200 [00:00<00:00, 1766.90it/s, Materializing param=vit.encoder.layer.0.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   8%|▊         | 17/200 [00:00<00:00, 1705.25it/s, Materializing param=vit.encoder.layer.0.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   9%|▉         | 18/200 [00:00<00:00, 1747.55it/s, Materializing param=vit.encoder.layer.0.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:   9%|▉         | 18/200 [00:00<00:00, 1695.47it/s, Materializing param=vit.encoder.layer.0.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|▉         | 19/200 [00:00<00:00, 1740.91it/s, Materializing param=vit.encoder.layer.0.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|▉         | 19/200 [00:00<00:00, 1700.45it/s, Materializing param=vit.encoder.layer.0.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|█         | 20/200 [00:00<00:00, 1748.57it/s, Materializing param=vit.encoder.layer.0.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|█         | 20/200 [00:00<00:00, 1706.39it/s, Materializing param=vit.encoder.layer.0.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|█         | 21/200 [00:00<00:00, 1749.50it/s, Materializing param=vit.encoder.layer.0.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  10%|█         | 21/200 [00:00<00:00, 1726.69it/s, Materializing param=vit.encoder.layer.0.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  11%|█         | 22/200 [00:00<00:00, 1780.78it/s, Materializing param=vit.encoder.layer.0.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  11%|█         | 22/200 [00:00<00:00, 1759.12it/s, Materializing param=vit.encoder.layer.0.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▏        | 23/200 [00:00<00:00, 1813.84it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▏        | 23/200 [00:00<00:00, 1794.14it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▏        | 24/200 [00:00<00:00, 1848.56it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▏        | 24/200 [00:00<00:00, 1829.18it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▎        | 25/200 [00:00<00:00, 1881.90it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  12%|█▎        | 25/200 [00:00<00:00, 1858.65it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  13%|█▎        | 26/200 [00:00<00:00, 1899.10it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  13%|█▎        | 26/200 [00:00<00:00, 1870.50it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▎        | 27/200 [00:00<00:00, 1909.52it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▎        | 27/200 [00:00<00:00, 1887.47it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▍        | 28/200 [00:00<00:00, 1929.65it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▍        | 28/200 [00:00<00:00, 1898.64it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▍        | 29/200 [00:00<00:00, 1943.11it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  14%|█▍        | 29/200 [00:00<00:00, 1914.03it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  15%|█▌        | 30/200 [00:00<00:00, 1940.94it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  15%|█▌        | 30/200 [00:00<00:00, 1911.02it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▌        | 31/200 [00:00<00:00, 1940.27it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▌        | 31/200 [00:00<00:00, 1908.32it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▌        | 32/200 [00:00<00:00, 1937.74it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▌        | 32/200 [00:00<00:00, 1909.49it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▋        | 33/200 [00:00<00:00, 1786.75it/s, Materializing param=vit.encoder.layer.1.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  16%|█▋        | 33/200 [00:00<00:00, 1760.03it/s, Materializing param=vit.encoder.layer.1.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  17%|█▋        | 34/200 [00:00<00:00, 1772.17it/s, Materializing param=vit.encoder.layer.1.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  17%|█▋        | 34/200 [00:00<00:00, 1748.23it/s, Materializing param=vit.encoder.layer.1.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 35/200 [00:00<00:00, 1760.90it/s, Materializing param=vit.encoder.layer.1.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 35/200 [00:00<00:00, 1744.64it/s, Materializing param=vit.encoder.layer.1.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 36/200 [00:00<00:00, 1764.00it/s, Materializing param=vit.encoder.layer.1.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 36/200 [00:00<00:00, 1748.82it/s, Materializing param=vit.encoder.layer.1.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 37/200 [00:00<00:00, 1778.43it/s, Materializing param=vit.encoder.layer.1.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  18%|█▊        | 37/200 [00:00<00:00, 1765.98it/s, Materializing param=vit.encoder.layer.1.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  19%|█▉        | 38/200 [00:00<00:00, 1796.30it/s, Materializing param=vit.encoder.layer.1.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  19%|█▉        | 38/200 [00:00<00:00, 1768.73it/s, Materializing param=vit.encoder.layer.1.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|█▉        | 39/200 [00:00<00:00, 1797.66it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|█▉        | 39/200 [00:00<00:00, 1785.92it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|██        | 40/200 [00:00<00:00, 1817.66it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|██        | 40/200 [00:00<00:00, 1805.65it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|██        | 41/200 [00:00<00:00, 1836.23it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  20%|██        | 41/200 [00:00<00:00, 1823.78it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  21%|██        | 42/200 [00:00<00:00, 1855.10it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  21%|██        | 42/200 [00:00<00:00, 1843.75it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▏       | 43/200 [00:00<00:00, 1874.01it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▏       | 43/200 [00:00<00:00, 1862.86it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▏       | 44/200 [00:00<00:00, 1892.33it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▏       | 44/200 [00:00<00:00, 1880.53it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▎       | 45/200 [00:00<00:00, 1909.80it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  22%|██▎       | 45/200 [00:00<00:00, 1898.70it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  23%|██▎       | 46/200 [00:00<00:00, 1927.01it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  23%|██▎       | 46/200 [00:00<00:00, 1916.27it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▎       | 47/200 [00:00<00:00, 1944.91it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▎       | 47/200 [00:00<00:00, 1933.54it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▍       | 48/200 [00:00<00:00, 1961.56it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▍       | 48/200 [00:00<00:00, 1950.35it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▍       | 49/200 [00:00<00:00, 1978.24it/s, Materializing param=vit.encoder.layer.2.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  24%|██▍       | 49/200 [00:00<00:00, 1967.10it/s, Materializing param=vit.encoder.layer.2.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  25%|██▌       | 50/200 [00:00<00:00, 1995.08it/s, Materializing param=vit.encoder.layer.2.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  25%|██▌       | 50/200 [00:00<00:00, 1984.30it/s, Materializing param=vit.encoder.layer.2.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▌       | 51/200 [00:00<00:00, 2011.07it/s, Materializing param=vit.encoder.layer.2.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▌       | 51/200 [00:00<00:00, 1999.92it/s, Materializing param=vit.encoder.layer.2.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▌       | 52/200 [00:00<00:00, 2026.31it/s, Materializing param=vit.encoder.layer.2.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▌       | 52/200 [00:00<00:00, 2015.60it/s, Materializing param=vit.encoder.layer.2.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▋       | 53/200 [00:00<00:00, 2041.79it/s, Materializing param=vit.encoder.layer.2.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  26%|██▋       | 53/200 [00:00<00:00, 2031.38it/s, Materializing param=vit.encoder.layer.2.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  27%|██▋       | 54/200 [00:00<00:00, 2056.95it/s, Materializing param=vit.encoder.layer.2.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  27%|██▋       | 54/200 [00:00<00:00, 2046.28it/s, Materializing param=vit.encoder.layer.2.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 55/200 [00:00<00:00, 2070.83it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 55/200 [00:00<00:00, 2060.35it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 56/200 [00:00<00:00, 2084.33it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 56/200 [00:00<00:00, 2074.17it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 57/200 [00:00<00:00, 2098.37it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  28%|██▊       | 57/200 [00:00<00:00, 2087.68it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  29%|██▉       | 58/200 [00:00<00:00, 2111.46it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  29%|██▉       | 58/200 [00:00<00:00, 2100.18it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|██▉       | 59/200 [00:00<00:00, 2123.64it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|██▉       | 59/200 [00:00<00:00, 2113.45it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|███       | 60/200 [00:00<00:00, 2136.61it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|███       | 60/200 [00:00<00:00, 2126.48it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|███       | 61/200 [00:00<00:00, 2149.30it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  30%|███       | 61/200 [00:00<00:00, 2138.65it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  31%|███       | 62/200 [00:00<00:00, 2161.42it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  31%|███       | 62/200 [00:00<00:00, 2151.39it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▏      | 63/200 [00:00<00:00, 2173.45it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▏      | 63/200 [00:00<00:00, 2163.84it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▏      | 64/200 [00:00<00:00, 2186.01it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▏      | 64/200 [00:00<00:00, 2174.90it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▎      | 65/200 [00:00<00:00, 2189.76it/s, Materializing param=vit.encoder.layer.3.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  32%|███▎      | 65/200 [00:00<00:00, 2178.28it/s, Materializing param=vit.encoder.layer.3.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  33%|███▎      | 66/200 [00:00<00:00, 2196.58it/s, Materializing param=vit.encoder.layer.3.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  33%|███▎      | 66/200 [00:00<00:00, 2184.60it/s, Materializing param=vit.encoder.layer.3.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▎      | 67/200 [00:00<00:00, 2198.77it/s, Materializing param=vit.encoder.layer.3.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▎      | 67/200 [00:00<00:00, 2183.70it/s, Materializing param=vit.encoder.layer.3.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▍      | 68/200 [00:00<00:00, 2201.51it/s, Materializing param=vit.encoder.layer.3.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▍      | 68/200 [00:00<00:00, 2190.46it/s, Materializing param=vit.encoder.layer.3.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▍      | 69/200 [00:00<00:00, 2209.30it/s, Materializing param=vit.encoder.layer.3.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  34%|███▍      | 69/200 [00:00<00:00, 2064.51it/s, Materializing param=vit.encoder.layer.3.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  35%|███▌      | 70/200 [00:00<00:00, 2072.45it/s, Materializing param=vit.encoder.layer.3.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  35%|███▌      | 70/200 [00:00<00:00, 2056.91it/s, Materializing param=vit.encoder.layer.3.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▌      | 71/200 [00:00<00:00, 2065.20it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▌      | 71/200 [00:00<00:00, 2049.87it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▌      | 72/200 [00:00<00:00, 2022.10it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▌      | 72/200 [00:00<00:00, 2006.24it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▋      | 73/200 [00:00<00:00, 2015.06it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  36%|███▋      | 73/200 [00:00<00:00, 2001.16it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  37%|███▋      | 74/200 [00:00<00:00, 2006.74it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  37%|███▋      | 74/200 [00:00<00:00, 1996.23it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 75/200 [00:00<00:00, 2008.37it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 75/200 [00:00<00:00, 1991.57it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 76/200 [00:00<00:00, 2004.86it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 76/200 [00:00<00:00, 1996.17it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 77/200 [00:00<00:00, 2012.68it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  38%|███▊      | 77/200 [00:00<00:00, 2003.92it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  39%|███▉      | 78/200 [00:00<00:00, 2017.75it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  39%|███▉      | 78/200 [00:00<00:00, 2007.20it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|███▉      | 79/200 [00:00<00:00, 2021.17it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|███▉      | 79/200 [00:00<00:00, 2011.14it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|████      | 80/200 [00:00<00:00, 2025.70it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|████      | 80/200 [00:00<00:00, 2016.19it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|████      | 81/200 [00:00<00:00, 2031.18it/s, Materializing param=vit.encoder.layer.4.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  40%|████      | 81/200 [00:00<00:00, 2023.35it/s, Materializing param=vit.encoder.layer.4.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  41%|████      | 82/200 [00:00<00:00, 2038.57it/s, Materializing param=vit.encoder.layer.4.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  41%|████      | 82/200 [00:00<00:00, 2030.42it/s, Materializing param=vit.encoder.layer.4.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▏     | 83/200 [00:00<00:00, 2044.15it/s, Materializing param=vit.encoder.layer.4.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▏     | 83/200 [00:00<00:00, 2015.32it/s, Materializing param=vit.encoder.layer.4.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▏     | 84/200 [00:00<00:00, 2029.86it/s, Materializing param=vit.encoder.layer.4.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▏     | 84/200 [00:00<00:00, 2022.33it/s, Materializing param=vit.encoder.layer.4.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▎     | 85/200 [00:00<00:00, 2037.09it/s, Materializing param=vit.encoder.layer.4.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  42%|████▎     | 85/200 [00:00<00:00, 2029.26it/s, Materializing param=vit.encoder.layer.4.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  43%|████▎     | 86/200 [00:00<00:00, 2044.40it/s, Materializing param=vit.encoder.layer.4.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  43%|████▎     | 86/200 [00:00<00:00, 2036.84it/s, Materializing param=vit.encoder.layer.4.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▎     | 87/200 [00:00<00:00, 2040.64it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▎     | 87/200 [00:00<00:00, 2033.41it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▍     | 88/200 [00:00<00:00, 2047.56it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▍     | 88/200 [00:00<00:00, 2040.20it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▍     | 89/200 [00:00<00:00, 2053.83it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  44%|████▍     | 89/200 [00:00<00:00, 2044.59it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  45%|████▌     | 90/200 [00:00<00:00, 2058.16it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  45%|████▌     | 90/200 [00:00<00:00, 2050.63it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▌     | 91/200 [00:00<00:00, 2063.23it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▌     | 91/200 [00:00<00:00, 2056.23it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▌     | 92/200 [00:00<00:00, 2068.72it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▌     | 92/200 [00:00<00:00, 2060.60it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▋     | 93/200 [00:00<00:00, 2073.85it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  46%|████▋     | 93/200 [00:00<00:00, 2066.10it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  47%|████▋     | 94/200 [00:00<00:00, 2060.95it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  47%|████▋     | 94/200 [00:00<00:00, 2054.20it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 95/200 [00:00<00:00, 2067.16it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 95/200 [00:00<00:00, 2057.03it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 96/200 [00:00<00:00, 2066.68it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 96/200 [00:00<00:00, 2058.95it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 97/200 [00:00<00:00, 2072.52it/s, Materializing param=vit.encoder.layer.5.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  48%|████▊     | 97/200 [00:00<00:00, 2065.82it/s, Materializing param=vit.encoder.layer.5.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  49%|████▉     | 98/200 [00:00<00:00, 2077.30it/s, Materializing param=vit.encoder.layer.5.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  49%|████▉     | 98/200 [00:00<00:00, 2068.53it/s, Materializing param=vit.encoder.layer.5.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|████▉     | 99/200 [00:00<00:00, 2078.60it/s, Materializing param=vit.encoder.layer.5.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|████▉     | 99/200 [00:00<00:00, 2055.48it/s, Materializing param=vit.encoder.layer.5.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|█████     | 100/200 [00:00<00:00, 2066.18it/s, Materializing param=vit.encoder.layer.5.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|█████     | 100/200 [00:00<00:00, 2058.24it/s, Materializing param=vit.encoder.layer.5.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|█████     | 101/200 [00:00<00:00, 2067.83it/s, Materializing param=vit.encoder.layer.5.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  50%|█████     | 101/200 [00:00<00:00, 2058.45it/s, Materializing param=vit.encoder.layer.5.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  51%|█████     | 102/200 [00:00<00:00, 2068.60it/s, Materializing param=vit.encoder.layer.5.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  51%|█████     | 102/200 [00:00<00:00, 2059.30it/s, Materializing param=vit.encoder.layer.5.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▏    | 103/200 [00:00<00:00, 2068.19it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▏    | 103/200 [00:00<00:00, 2059.22it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▏    | 104/200 [00:00<00:00, 2068.42it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▏    | 104/200 [00:00<00:00, 2058.97it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▎    | 105/200 [00:00<00:00, 2068.32it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  52%|█████▎    | 105/200 [00:00<00:00, 2060.52it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  53%|█████▎    | 106/200 [00:00<00:00, 2071.35it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  53%|█████▎    | 106/200 [00:00<00:00, 2063.85it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  54%|█████▎    | 107/200 [00:00<00:00, 2073.17it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  54%|█████▎    | 107/200 [00:00<00:00, 2064.63it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  54%|█████▍    | 108/200 [00:00<00:00, 2074.51it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  54%|█████▍    | 108/200 [00:00<00:00, 2035.57it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  55%|█████▍    | 109/200 [00:00<00:00, 2038.35it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  55%|█████▍    | 109/200 [00:00<00:00, 2029.01it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  55%|█████▌    | 110/200 [00:00<00:00, 2037.16it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  55%|█████▌    | 110/200 [00:00<00:00, 2028.87it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▌    | 111/200 [00:00<00:00, 2037.74it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▌    | 111/200 [00:00<00:00, 2031.72it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▌    | 112/200 [00:00<00:00, 2043.42it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▌    | 112/200 [00:00<00:00, 2038.23it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▋    | 113/200 [00:00<00:00, 2049.66it/s, Materializing param=vit.encoder.layer.6.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  56%|█████▋    | 113/200 [00:00<00:00, 2043.75it/s, Materializing param=vit.encoder.layer.6.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  57%|█████▋    | 114/200 [00:00<00:00, 2054.63it/s, Materializing param=vit.encoder.layer.6.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  57%|█████▋    | 114/200 [00:00<00:00, 2047.19it/s, Materializing param=vit.encoder.layer.6.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  57%|█████▊    | 115/200 [00:00<00:00, 2057.36it/s, Materializing param=vit.encoder.layer.6.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  57%|█████▊    | 115/200 [00:00<00:00, 2050.56it/s, Materializing param=vit.encoder.layer.6.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  58%|█████▊    | 116/200 [00:00<00:00, 2062.04it/s, Materializing param=vit.encoder.layer.6.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  58%|█████▊    | 116/200 [00:00<00:00, 2055.43it/s, Materializing param=vit.encoder.layer.6.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  58%|█████▊    | 117/200 [00:00<00:00, 2065.79it/s, Materializing param=vit.encoder.layer.6.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  58%|█████▊    | 117/200 [00:00<00:00, 2059.40it/s, Materializing param=vit.encoder.layer.6.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  59%|█████▉    | 118/200 [00:00<00:00, 2069.41it/s, Materializing param=vit.encoder.layer.6.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  59%|█████▉    | 118/200 [00:00<00:00, 2062.72it/s, Materializing param=vit.encoder.layer.6.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|█████▉    | 119/200 [00:00<00:00, 2073.27it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|█████▉    | 119/200 [00:00<00:00, 2066.49it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|██████    | 120/200 [00:00<00:00, 2076.50it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|██████    | 120/200 [00:00<00:00, 2070.34it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|██████    | 121/200 [00:00<00:00, 2080.69it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  60%|██████    | 121/200 [00:00<00:00, 2074.18it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  61%|██████    | 122/200 [00:00<00:00, 2083.20it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  61%|██████    | 122/200 [00:00<00:00, 2077.86it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▏   | 123/200 [00:00<00:00, 2088.20it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▏   | 123/200 [00:00<00:00, 2082.41it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▏   | 124/200 [00:00<00:00, 2090.25it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▏   | 124/200 [00:00<00:00, 2083.90it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▎   | 125/200 [00:00<00:00, 2093.74it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  62%|██████▎   | 125/200 [00:00<00:00, 2088.26it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  63%|██████▎   | 126/200 [00:00<00:00, 2098.86it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  63%|██████▎   | 126/200 [00:00<00:00, 2093.65it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▎   | 127/200 [00:00<00:00, 2104.27it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▎   | 127/200 [00:00<00:00, 2098.84it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▍   | 128/200 [00:00<00:00, 2109.19it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▍   | 128/200 [00:00<00:00, 2104.17it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▍   | 129/200 [00:00<00:00, 2114.57it/s, Materializing param=vit.encoder.layer.7.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  64%|██████▍   | 129/200 [00:00<00:00, 2109.65it/s, Materializing param=vit.encoder.layer.7.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  65%|██████▌   | 130/200 [00:00<00:00, 2120.03it/s, Materializing param=vit.encoder.layer.7.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  65%|██████▌   | 130/200 [00:00<00:00, 2114.82it/s, Materializing param=vit.encoder.layer.7.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▌   | 131/200 [00:00<00:00, 2125.26it/s, Materializing param=vit.encoder.layer.7.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▌   | 131/200 [00:00<00:00, 2120.58it/s, Materializing param=vit.encoder.layer.7.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▌   | 132/200 [00:00<00:00, 2130.78it/s, Materializing param=vit.encoder.layer.7.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▌   | 132/200 [00:00<00:00, 2125.54it/s, Materializing param=vit.encoder.layer.7.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▋   | 133/200 [00:00<00:00, 2135.68it/s, Materializing param=vit.encoder.layer.7.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  66%|██████▋   | 133/200 [00:00<00:00, 2130.32it/s, Materializing param=vit.encoder.layer.7.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  67%|██████▋   | 134/200 [00:00<00:00, 2140.40it/s, Materializing param=vit.encoder.layer.7.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  67%|██████▋   | 134/200 [00:00<00:00, 2135.44it/s, Materializing param=vit.encoder.layer.7.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 135/200 [00:00<00:00, 2145.46it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 135/200 [00:00<00:00, 2140.52it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 136/200 [00:00<00:00, 2150.55it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 136/200 [00:00<00:00, 2145.37it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 137/200 [00:00<00:00, 2154.03it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  68%|██████▊   | 137/200 [00:00<00:00, 2146.06it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  69%|██████▉   | 138/200 [00:00<00:00, 2137.21it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  69%|██████▉   | 138/200 [00:00<00:00, 2071.56it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|██████▉   | 139/200 [00:00<00:00, 2076.33it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|██████▉   | 139/200 [00:00<00:00, 2068.92it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|███████   | 140/200 [00:00<00:00, 2074.06it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|███████   | 140/200 [00:00<00:00, 2067.36it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|███████   | 141/200 [00:00<00:00, 2074.41it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  70%|███████   | 141/200 [00:00<00:00, 2068.75it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  71%|███████   | 142/200 [00:00<00:00, 2075.47it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  71%|███████   | 142/200 [00:00<00:00, 2059.49it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▏  | 143/200 [00:00<00:00, 2056.95it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▏  | 143/200 [00:00<00:00, 2046.93it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▏  | 144/200 [00:00<00:00, 2051.91it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▏  | 144/200 [00:00<00:00, 2041.62it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▎  | 145/200 [00:00<00:00, 2047.46it/s, Materializing param=vit.encoder.layer.8.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  72%|███████▎  | 145/200 [00:00<00:00, 2042.39it/s, Materializing param=vit.encoder.layer.8.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  73%|███████▎  | 146/200 [00:00<00:00, 2049.03it/s, Materializing param=vit.encoder.layer.8.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  73%|███████▎  | 146/200 [00:00<00:00, 2030.88it/s, Materializing param=vit.encoder.layer.8.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▎  | 147/200 [00:00<00:00, 2038.11it/s, Materializing param=vit.encoder.layer.8.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▎  | 147/200 [00:00<00:00, 2033.63it/s, Materializing param=vit.encoder.layer.8.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▍  | 148/200 [00:00<00:00, 2040.82it/s, Materializing param=vit.encoder.layer.8.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▍  | 148/200 [00:00<00:00, 2032.57it/s, Materializing param=vit.encoder.layer.8.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▍  | 149/200 [00:00<00:00, 2015.25it/s, Materializing param=vit.encoder.layer.8.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  74%|███████▍  | 149/200 [00:00<00:00, 2003.52it/s, Materializing param=vit.encoder.layer.8.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  75%|███████▌  | 150/200 [00:00<00:00, 2006.77it/s, Materializing param=vit.encoder.layer.8.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  75%|███████▌  | 150/200 [00:00<00:00, 1993.84it/s, Materializing param=vit.encoder.layer.8.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▌  | 151/200 [00:00<00:00, 1994.49it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▌  | 151/200 [00:00<00:00, 1986.88it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▌  | 152/200 [00:00<00:00, 1994.47it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▌  | 152/200 [00:00<00:00, 1989.94it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▋  | 153/200 [00:00<00:00, 1997.70it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  76%|███████▋  | 153/200 [00:00<00:00, 1993.79it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  77%|███████▋  | 154/200 [00:00<00:00, 2001.89it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  77%|███████▋  | 154/200 [00:00<00:00, 1991.48it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 155/200 [00:00<00:00, 1999.27it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 155/200 [00:00<00:00, 1995.39it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 156/200 [00:00<00:00, 2003.68it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 156/200 [00:00<00:00, 1999.61it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 157/200 [00:00<00:00, 2007.25it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  78%|███████▊  | 157/200 [00:00<00:00, 2003.00it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  79%|███████▉  | 158/200 [00:00<00:00, 2011.13it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  79%|███████▉  | 158/200 [00:00<00:00, 2007.32it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|███████▉  | 159/200 [00:00<00:00, 2015.47it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|███████▉  | 159/200 [00:00<00:00, 2011.66it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|████████  | 160/200 [00:00<00:00, 2019.61it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|████████  | 160/200 [00:00<00:00, 2015.68it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|████████  | 161/200 [00:00<00:00, 2023.84it/s, Materializing param=vit.encoder.layer.9.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  80%|████████  | 161/200 [00:00<00:00, 2020.02it/s, Materializing param=vit.encoder.layer.9.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  81%|████████  | 162/200 [00:00<00:00, 2028.50it/s, Materializing param=vit.encoder.layer.9.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  81%|████████  | 162/200 [00:00<00:00, 2024.14it/s, Materializing param=vit.encoder.layer.9.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▏ | 163/200 [00:00<00:00, 2030.41it/s, Materializing param=vit.encoder.layer.9.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▏ | 163/200 [00:00<00:00, 2024.36it/s, Materializing param=vit.encoder.layer.9.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▏ | 164/200 [00:00<00:00, 2030.23it/s, Materializing param=vit.encoder.layer.9.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▏ | 164/200 [00:00<00:00, 2024.78it/s, Materializing param=vit.encoder.layer.9.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▎ | 165/200 [00:00<00:00, 2030.97it/s, Materializing param=vit.encoder.layer.9.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  82%|████████▎ | 165/200 [00:00<00:00, 2024.29it/s, Materializing param=vit.encoder.layer.9.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  83%|████████▎ | 166/200 [00:00<00:00, 2029.41it/s, Materializing param=vit.encoder.layer.9.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  83%|████████▎ | 166/200 [00:00<00:00, 2023.70it/s, Materializing param=vit.encoder.layer.9.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▎ | 167/200 [00:00<00:00, 2027.17it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▎ | 167/200 [00:00<00:00, 2021.14it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▍ | 168/200 [00:00<00:00, 2026.85it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▍ | 168/200 [00:00<00:00, 2021.44it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▍ | 169/200 [00:00<00:00, 2027.64it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  84%|████████▍ | 169/200 [00:00<00:00, 2022.60it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  85%|████████▌ | 170/200 [00:00<00:00, 2028.91it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  85%|████████▌ | 170/200 [00:00<00:00, 2024.39it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▌ | 171/200 [00:00<00:00, 2030.80it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▌ | 171/200 [00:00<00:00, 2025.48it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▌ | 172/200 [00:00<00:00, 2032.45it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▌ | 172/200 [00:00<00:00, 2028.46it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▋ | 173/200 [00:00<00:00, 2035.79it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  86%|████████▋ | 173/200 [00:00<00:00, 2031.90it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  87%|████████▋ | 174/200 [00:00<00:00, 2039.17it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  87%|████████▋ | 174/200 [00:00<00:00, 2035.19it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 175/200 [00:00<00:00, 2042.60it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 175/200 [00:00<00:00, 2039.25it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 176/200 [00:00<00:00, 2046.92it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 176/200 [00:00<00:00, 2043.57it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 177/200 [00:00<00:00, 2051.06it/s, Materializing param=vit.encoder.layer.10.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  88%|████████▊ | 177/200 [00:00<00:00, 2047.27it/s, Materializing param=vit.encoder.layer.10.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  89%|████████▉ | 178/200 [00:00<00:00, 2054.91it/s, Materializing param=vit.encoder.layer.10.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  89%|████████▉ | 178/200 [00:00<00:00, 2051.61it/s, Materializing param=vit.encoder.layer.10.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|████████▉ | 179/200 [00:00<00:00, 2059.40it/s, Materializing param=vit.encoder.layer.10.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|████████▉ | 179/200 [00:00<00:00, 2056.20it/s, Materializing param=vit.encoder.layer.10.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|█████████ | 180/200 [00:00<00:00, 2063.95it/s, Materializing param=vit.encoder.layer.10.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|█████████ | 180/200 [00:00<00:00, 2060.55it/s, Materializing param=vit.encoder.layer.10.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|█████████ | 181/200 [00:00<00:00, 2068.07it/s, Materializing param=vit.encoder.layer.10.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  90%|█████████ | 181/200 [00:00<00:00, 2064.75it/s, Materializing param=vit.encoder.layer.10.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  91%|█████████ | 182/200 [00:00<00:00, 2072.45it/s, Materializing param=vit.encoder.layer.10.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  91%|█████████ | 182/200 [00:00<00:00, 2069.26it/s, Materializing param=vit.encoder.layer.10.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▏| 183/200 [00:00<00:00, 2076.32it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▏| 183/200 [00:00<00:00, 2071.89it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▏| 184/200 [00:00<00:00, 2078.41it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▏| 184/200 [00:00<00:00, 2074.42it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▎| 185/200 [00:00<00:00, 2080.81it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  92%|█████████▎| 185/200 [00:00<00:00, 2077.32it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  93%|█████████▎| 186/200 [00:00<00:00, 2083.95it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  93%|█████████▎| 186/200 [00:00<00:00, 2079.99it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▎| 187/200 [00:00<00:00, 2086.84it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.bias]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▎| 187/200 [00:00<00:00, 2083.39it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▍| 188/200 [00:00<00:00, 2090.52it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▍| 188/200 [00:00<00:00, 2087.10it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▍| 189/200 [00:00<00:00, 2093.82it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  94%|█████████▍| 189/200 [00:00<00:00, 2090.21it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  95%|█████████▌| 190/200 [00:00<00:00, 2096.85it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  95%|█████████▌| 190/200 [00:00<00:00, 2093.24it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▌| 191/200 [00:00<00:00, 2100.01it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▌| 191/200 [00:00<00:00, 2096.41it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▌| 192/200 [00:00<00:00, 2102.81it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▌| 192/200 [00:00<00:00, 2099.27it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▋| 193/200 [00:00<00:00, 2106.11it/s, Materializing param=vit.encoder.layer.11.layernorm_after.bias]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  96%|█████████▋| 193/200 [00:00<00:00, 2102.58it/s, Materializing param=vit.encoder.layer.11.layernorm_after.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  97%|█████████▋| 194/200 [00:00<00:00, 2109.22it/s, Materializing param=vit.encoder.layer.11.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  97%|█████████▋| 194/200 [00:00<00:00, 2105.83it/s, Materializing param=vit.encoder.layer.11.layernorm_after.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 195/200 [00:00<00:00, 2112.44it/s, Materializing param=vit.encoder.layer.11.layernorm_before.bias] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 195/200 [00:00<00:00, 2108.85it/s, Materializing param=vit.encoder.layer.11.layernorm_before.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 196/200 [00:00<00:00, 2115.46it/s, Materializing param=vit.encoder.layer.11.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 196/200 [00:00<00:00, 2112.01it/s, Materializing param=vit.encoder.layer.11.layernorm_before.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 197/200 [00:00<00:00, 2118.63it/s, Materializing param=vit.encoder.layer.11.output.dense.bias]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  98%|█████████▊| 197/200 [00:00<00:00, 2115.15it/s, Materializing param=vit.encoder.layer.11.output.dense.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  99%|█████████▉| 198/200 [00:00<00:00, 2121.49it/s, Materializing param=vit.encoder.layer.11.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights:  99%|█████████▉| 198/200 [00:00<00:00, 2118.07it/s, Materializing param=vit.encoder.layer.11.output.dense.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights: 100%|█████████▉| 199/200 [00:00<00:00, 2124.86it/s, Materializing param=vit.layernorm.bias]                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights: 100%|█████████▉| 199/200 [00:00<00:00, 2121.60it/s, Materializing param=vit.layernorm.bias]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights: 100%|██████████| 200/200 [00:00<00:00, 2128.35it/s, Materializing param=vit.layernorm.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights: 100%|██████████| 200/200 [00:00<00:00, 2125.02it/s, Materializing param=vit.layernorm.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading weights: 100%|██████████| 200/200 [00:00<00:00, 2120.44it/s, Materializing param=vit.layernorm.weight]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class HuggingFaceClassifier:\n",
    "    \"\"\"MAITE wrapper for HuggingFaceClassifier.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, device: str) -> None:\n",
    "        \"\"\"Initialize HuggingFaceClassifier.\"\"\"\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "        self.model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        self.metadata = self.model.config.id2label\n",
    "\n",
    "    def __call__(self, batch: Sequence[ic.InputType]) -> Sequence[ic.TargetType]:\n",
    "        \"\"\"Run classifier for batch and return results.\"\"\"\n",
    "        # tensor bridging\n",
    "        input_tensor = torch.as_tensor(batch)\n",
    "        if input_tensor.ndim != 4:\n",
    "            raise ValueError(f\"Invalid input dimensions. Expected 4, got {input_tensor.ndim}\")\n",
    "\n",
    "        # preprocess\n",
    "        hf_inputs = self.image_processor(input_tensor, return_tensors=\"pt\")\n",
    "\n",
    "        # put on device\n",
    "        hf_inputs = hf_inputs.to(self.device)\n",
    "\n",
    "        # get predictions\n",
    "        with torch.no_grad():\n",
    "            return self.model(**hf_inputs).logits.softmax(1).detach().cpu()\n",
    "\n",
    "\n",
    "jatic_classifier: ic.Model = HuggingFaceClassifier(\n",
    "    model_name=\"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935845f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:52.912131Z",
     "iopub.status.busy": "2026-02-17T02:01:52.911989Z",
     "iopub.status.idle": "2026-02-17T02:01:52.914119Z",
     "shell.execute_reply": "2026-02-17T02:01:52.913660Z"
    },
    "papermill": {
     "duration": 0.015097,
     "end_time": "2026-02-17T02:01:52.914829",
     "exception": false,
     "start_time": "2026-02-17T02:01:52.899732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = [int(k) for k in jatic_classifier.metadata]\n",
    "classifier = JATICImageClassifier(classifier=jatic_classifier, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319a32a",
   "metadata": {
    "papermill": {
     "duration": 0.010122,
     "end_time": "2026-02-17T02:01:52.935113",
     "exception": false,
     "start_time": "2026-02-17T02:01:52.924991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Saliency Generator <a name=\"saliency-generator\"></a>\n",
    "\n",
    "We'll use the `SlidingWindowStack` blackbox saliency generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c54b646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:52.959504Z",
     "iopub.status.busy": "2026-02-17T02:01:52.959366Z",
     "iopub.status.idle": "2026-02-17T02:01:52.961541Z",
     "shell.execute_reply": "2026-02-17T02:01:52.960946Z"
    },
    "papermill": {
     "duration": 0.014997,
     "end_time": "2026-02-17T02:01:52.962037",
     "exception": false,
     "start_time": "2026-02-17T02:01:52.947040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sal_generator = SlidingWindowStack(window_size=(2, 2), stride=(1, 1), threads=4)\n",
    "sal_generator.fill = (128, 128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c311e",
   "metadata": {
    "papermill": {
     "duration": 0.009713,
     "end_time": "2026-02-17T02:01:52.981700",
     "exception": false,
     "start_time": "2026-02-17T02:01:52.971987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results <a name=\"results\"></a>\n",
    "\n",
    "Note: for clarity, we'll only be performing the saliency analysis with respect to the groundtruth class, but this analysis could also be applied to the predicted class, which may be useful in cases where the groundtruth and predictions may differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1a326",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b87f23da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:01:53.003541Z",
     "iopub.status.busy": "2026-02-17T02:01:53.003358Z",
     "iopub.status.idle": "2026-02-17T02:04:09.538039Z",
     "shell.execute_reply": "2026-02-17T02:04:09.537267Z"
    },
    "papermill": {
     "duration": 136.546258,
     "end_time": "2026-02-17T02:04:09.538697",
     "exception": true,
     "start_time": "2026-02-17T02:01:52.992439",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating saliency maps for reference image (image 1 of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating saliency maps for s_y=0.0001 (ref image 1 of 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'img_gsd' must be provided for this perturber",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mgenerate_perturbed_sal_maps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_classifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msaliency_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43msal_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjatic_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.4e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms_x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mgenerate_perturbed_sal_maps\u001b[39m\u001b[34m(images, ground_truth, image_classifier, saliency_generator, kwargs, display_labels, display_maps, metrics)\u001b[39m\n\u001b[32m     55\u001b[39m     pred_class = _max_class(probs)\n\u001b[32m     56\u001b[39m     res = SaliencyResults(\n\u001b[32m     57\u001b[39m         ref_img=np.copy(img),\n\u001b[32m     58\u001b[39m         ref_sal_maps=sal_maps,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m         pred_prob=probs[pred_class],\n\u001b[32m     62\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43m_generate_augmented_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     results.append(res)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Plot each image in set with saliency maps\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36m_generate_augmented_maps\u001b[39m\u001b[34m(idx, kwargs, res, img, num_images, image_classifier, saliency_generator)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating saliency maps for s_y=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk[\u001b[33m'\u001b[39m\u001b[33ms_y\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (ref image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_images\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m xform = JitterPerturber(**k)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m img_out, _ = \u001b[43mxform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m sal_maps = saliency_generator(img_out, image_classifier)\n\u001b[32m     21\u001b[39m probs = \u001b[38;5;28mnext\u001b[39m(image_classifier.classify_images(np.expand_dims(img_out, axis=\u001b[32m0\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uncontrolled/projects/CDAO/gitlab/nrtk/.tox/papermill/lib/python3.13/site-packages/nrtk/interfaces/perturb_image.py:143\u001b[39m, in \u001b[36mPerturbImage.__call__\u001b[39m\u001b[34m(self, image, boxes, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    136\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    137\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m     **kwargs: Any,\n\u001b[32m    141\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray[Any, Any], Iterable[\u001b[38;5;28mtuple\u001b[39m[AxisAlignedBoundingBox, \u001b[38;5;28mdict\u001b[39m[Hashable, \u001b[38;5;28mfloat\u001b[39m]]] | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    142\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calls ``perturb()`` with the given input image.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uncontrolled/projects/CDAO/gitlab/nrtk/.tox/papermill/lib/python3.13/site-packages/nrtk/impls/perturb_image/optical/_pybsm/pybsm_perturber_mixin.py:354\u001b[39m, in \u001b[36mPybsmPerturberMixin.perturb\u001b[39m\u001b[34m(self, image, boxes, img_gsd, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m image, boxes = \u001b[38;5;28msuper\u001b[39m().perturb(image=image, boxes=boxes, **kwargs)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img_gsd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mimg_gsd\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be provided for this perturber\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_default_psf:\n\u001b[32m    357\u001b[39m     img_gsd = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: 'img_gsd' must be provided for this perturber"
     ]
    }
   ],
   "source": [
    "results = generate_perturbed_sal_maps(\n",
    "    images=imgs,\n",
    "    ground_truth=ground_truth,\n",
    "    image_classifier=classifier,\n",
    "    saliency_generator=sal_generator,\n",
    "    display_labels={int(k): str(v) for k, v in jatic_classifier.metadata.items()},\n",
    "    kwargs=[{\"s_y\": 1e-4, \"s_x\": 0.0}, {\"s_y\": 1.2e-4, \"s_x\": 0.0}, {\"s_y\": 1.4e-4, \"s_x\": 0.0}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e2421",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can visually see that as the quality of the input image degrades (more perturbation), the quality of the generated saliency maps similarly degrades.\n",
    "\n",
    "In an attempt to quantify these differences, we've also computed several metrics:\n",
    "\n",
    "#### Entropy <a name=\"entropy\"></a>\n",
    "\n",
    "If we compare entropy values using both positive and negative saliency we don't see much of a change across degradations. This is likely due to negative and positive saliency \"fighting\" each other as degradation increases (as one increases, the other decreases).\n",
    "\n",
    "If we consider entropy values computed from only positive or only negative saliency values, we see differences in values. Looking at the dominant saliency type (i.e. positive/blue) for the ship, we can see that as degradation gets worse, entropy increases -- to a certain point. The reduction in entropy likely corresponds to the classifier being less able to identify key features that led to the original probability distribution for the reference image due to the degradion. Eventually these features may become so degraded that the classifier begins predicting with very low confidence. Looking at the domainant saliency type (i.e. negative/red) for the cat, we see similar changes as the other reference image; however, the positive and negative saliencies are significantly closer. This could be a sign of less definitve features used for identificantion. Since this does not c\n",
    "\n",
    "If we look at the opposite saliency type for each reference image, we see a very slight decrease in entropy as degradation increases. This potentially indicates that the degradation introduces noise that the classifier misidentifies as a contraindicator for the ground truth class, but more likely corresponds to the classifier predicting with less confidence due to the loss in higher quality features.\n",
    "\n",
    "#### Sum of Squared Differences (SSD) <a name=\"SSD\"></a> \n",
    "(0 is most similar) The sum of squared differences lets us quantitatively confirm that as degradation gets worse, saliency maps are increasiningly dissimilar to the original reference saliency map. However, the metric doesn't give us much insight into what is actually happening to create these differences.\n",
    "\n",
    "#### Cross-Correlation (XCorr) <a name=\"XCorr\"></a>  \n",
    "(1 is most similar) Cross-correlations tell us similar information as SSD. The introduction of negative correlation values, however, potentially indicates that the saliency maps begin to become the \"opposite\" of the original reference saliency maps. The aligns with the pattern we saw with positive/negative saliency entropy -- we see an introduction of the opposite saliency as the image becomes more degraded and the classifier becomes more confused. The likely doesn't occur with the ship reference image as it was more strongly salient in one direction compared to the cat reference image was contained a more balanced mix of both positive and negative saliency.\n",
    "\n",
    "While aspects of model explainability and model robustness have previously been studied independently, this notebook demonstrates a preliminary exploration of their relationship through quantification of how saliency maps change due to various perturbations. Future work will explore whether quantitative changes in the structure and quality of saliency maps provide a mechanism for understanding model failure modes and edge cases due to various perturbations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 284.484834,
   "end_time": "2026-02-17T02:04:10.768577",
   "environment_variables": {},
   "exception": true,
   "input_path": "docs/examples/maite/jatic-perturbations-saliency.ipynb",
   "output_path": "docs/examples/maite/jatic-perturbations-saliency.ipynb",
   "parameters": {},
   "start_time": "2026-02-17T01:59:26.283743",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
